{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "from optimizer import *\n",
    "from LookAhead import LookAheadOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quad_10(x):\n",
    "    return np.sum(x**2)\n",
    "\n",
    "def rosen(x, a=1, b=5):\n",
    "    n = len(x)\n",
    "    return np.sum((a - x[:-1])**2 + b*(x[1:]- x[:-1]**2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(opt, func, x, k=2000):\n",
    "    p = np.zeros((k+1, 10))\n",
    "    p[0] = x\n",
    "    \n",
    "    for i in range(k):\n",
    "        x = opt.step(func, x)\n",
    "        p[i+1] = x\n",
    "    \n",
    "    return p\n",
    "\n",
    "def evaluate(optimizer, func, num_x, N=100, tol=1e-10):\n",
    "    data = {'abs_err':np.zeros(N), 'abs_err_func':np.zeros(N),\n",
    "           'num_func_eval': np.zeros(N), 'time':np.zeros(N)}\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        x = np.zeros(num_x)\n",
    "        for k in range(num_x):\n",
    "            sign = np.random.choice([1, -1])\n",
    "            y = np.random.random() * 4 - 2\n",
    "            x[k] = sign * np.exp(y)\n",
    "        \n",
    "        diff = np.Inf\n",
    "        diffval = np.Inf\n",
    "        n = 0\n",
    "        t = 0\n",
    "        \n",
    "        while diffval > tol:\n",
    "            tict = time.time()\n",
    "            nx = optimizer.step(func, x)\n",
    "            elapsed_time = time.time() - tict\n",
    "            diff = np.linalg.norm(nx-x)\n",
    "            diffval = np.abs(func(nx)-func(x))\n",
    "            n += 1\n",
    "            t += elapsed_time\n",
    "            \n",
    "            x = nx\n",
    "            print(x)\n",
    "        data['abs_err'][i] = diff\n",
    "        data['abs_err_func'][i] = diffval\n",
    "        data['num_func_eval'][i] = n\n",
    "        data['time'][i] = t\n",
    "        \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(x):\n",
    "    return np.array([np.sum(x) - 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = AdamOpt(10)\n",
    "momentum = MomemtunOpt(10)\n",
    "lagrange = ArgumentedLagrange(h, 1)\n",
    "\n",
    "lookahead_adam = LookAheadOpt(adam)\n",
    "lookahead_mom = LookAheadOpt(momentum)\n",
    "lookahead_lag = LookAheadOpt(lagrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.87574705  0.81205771  0.72805109  0.61117346  0.46126989  0.3036976\n",
      "  0.18370667  0.12113899  0.07869295 -0.09769866]\n",
      "[ 0.38841084  0.18311325  0.07790553  0.05310147  0.05016298  0.04988084\n",
      "  0.04976208  0.04871185  0.03679278 -0.14602215]\n",
      "[ 0.76139581  0.62280771  0.45290174  0.28121137  0.1602749   0.10861303\n",
      "  0.0945575   0.08827049  0.06621092 -0.10894591]\n",
      "[ 0.62944824  0.4362434   0.24969762  0.13011973  0.08731937  0.07848435\n",
      "  0.07674571  0.07402251  0.05586884 -0.12140261]\n",
      "[ 0.71188576  0.54879573  0.36424558  0.20592437  0.11981282  0.09287006\n",
      "  0.08687025  0.08273255  0.06230502 -0.1135627 ]\n",
      "[ 0.67010044  0.49008124  0.30145692  0.16146514  0.10000922  0.08466794\n",
      "  0.08154742  0.07828229  0.05903853 -0.11750955]\n",
      "[ 0.6941725   0.52349097  0.33636718  0.18529538  0.11029752  0.08906061\n",
      "  0.08454259  0.08083269  0.06091967 -0.11522734]\n",
      "[ 0.68119261  0.50533674  0.31712875  0.17188944  0.10442409  0.08659973\n",
      "  0.08290675  0.07945323  0.05990346 -0.1164583 ]\n",
      "[ 0.68845     0.51544984  0.32776469  0.17921934  0.10760904  0.08794935\n",
      "  0.08381783  0.08022588  0.06047384 -0.11576684]\n",
      "[ 0.68448026  0.50990392  0.32190861  0.17515766  0.10583477  0.08720029\n",
      "  0.0833158   0.07980122  0.0601602  -0.1161464 ]\n",
      "[ 0.68667399  0.51296467  0.3251352   0.17738782  0.10680725  0.08761281\n",
      "  0.08359509  0.08003679  0.06033437 -0.11593511]\n",
      "[ 0.6854746   0.51128858  0.32336613  0.17616241  0.10627122  0.08738383\n",
      "  0.08343966  0.07990669  0.06023792 -0.11605273]\n",
      "[ 0.68612755  0.51219896  0.32432716  0.17682716  0.10656196  0.08750838\n",
      "  0.08352466  0.07997816  0.06029031 -0.11598819]\n",
      "[ 0.68578234  0.51171359  0.32381854  0.17647293  0.10640549  0.08744073\n",
      "  0.08347782  0.07993826  0.06026047 -0.11602428]\n",
      "[ 0.68595408  0.51196131  0.32407251  0.17665264  0.10648772  0.08747785\n",
      "  0.08350488  0.07996151  0.06027816 -0.11600242]\n",
      "[ 0.68587636  0.51184404  0.32395489  0.17656729  0.10644747  0.08745773\n",
      "  0.0834917   0.07995075  0.06026914 -0.11601491]\n",
      "[ 0.68590724  0.51188775  0.32400173  0.17660129  0.10646551  0.08746813\n",
      "  0.08349794  0.07995561  0.06027435 -0.11600762]\n",
      "[ 0.68590238  0.51188428  0.32399618  0.17659713  0.10646065  0.08746397\n",
      "  0.08349378  0.07995179  0.06027123 -0.11601179]\n",
      "[ 0.68589961  0.51188428  0.32399063  0.17659436  0.10646065  0.08746397\n",
      "  0.08349378  0.07995179  0.06027123 -0.11601179]\n",
      "[ 0.68589995  0.51188186  0.32399097  0.17659401  0.10645961  0.08746432\n",
      "  0.08349343  0.07995214  0.06027157 -0.11601144]\n",
      "[ 0.6859003   0.51188082  0.32399132  0.17659401  0.10645996  0.08746467\n",
      "  0.08349378  0.07995249  0.06027192 -0.11601109]\n",
      "[ 0.68589995  0.51188116  0.32399132  0.17659436  0.10645996  0.08746501\n",
      "  0.08349447  0.07995283  0.06027227 -0.11601109]\n",
      "[ 0.68589995  0.51188116  0.32399132  0.17659436  0.10645996  0.08746501\n",
      "  0.08349447  0.07995283  0.06027227 -0.11601109]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'abs_err': array([0.]),\n",
       " 'abs_err_func': array([0.]),\n",
       " 'num_func_eval': array([23.]),\n",
       " 'time': array([2.63235188])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(lagrange, rosen, 10, N=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x = 10\n",
    "x = np.zeros(num_x)\n",
    "for k in range(num_x):\n",
    "    sign = np.random.choice([1, -1])\n",
    "    y = np.random.random() * 4 - 2\n",
    "    x[k] = sign * np.exp(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = np.ones(4)\n",
    "k = np.ones(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(lam, 2*k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from methods import gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x[0]**2 - x[1]*x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(f, x, h=1e-10):\n",
    "    '''\n",
    "    Calculate the gradient of f at x by using forward difference\n",
    "\n",
    "    Args:\n",
    "        f: function that want to find the gradient\n",
    "        x: the position where want to find the gradient\n",
    "\n",
    "    Returns:\n",
    "        grad: an array of gradients for each dimension\n",
    "    '''\n",
    "    temp = []\n",
    "    N = len(x)\n",
    "\n",
    "    for i in range(N):\n",
    "        xx = np.copy(x)\n",
    "        \n",
    "        xx[i] += h\n",
    "        print(xx)\n",
    "        print((f(xx) - f(x)) / h)\n",
    "        temp.append((f(xx) - f(x)) / h)\n",
    "\n",
    "    return np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n",
      "1.000000082740371\n",
      "[1. 1.]\n",
      "-1.000000082740371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.00000008, -1.00000008])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(f, [1.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x[0]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(f, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
